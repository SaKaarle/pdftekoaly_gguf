# PDF RAG Embedded koodi
  

- Esimerkki Python skripti sovelluksista, joilla yritet√§√§n ker√§t√§ dataa PDF-tiedostoista, k√§ytt√§m√§ll√§ eri methodeja, kuten llama-cpp-python rakennettua "embedded" toimitoa.
- Testattu my√∂s CHUNKien optimointia.
  
  
Toistaiseksi on vain testattu yhdell√§ PDF tiedostolla embedding ominaisuutta ja my√∂s testattu eri embed malleja: `all-MiniLM-L6-v2.Q4_K_M.gguf` sek√§ `nomic-embed-text-v1.5.Q8_0.gguf`. T√§m√§n j√§lkeen lis√§t√§√§ tarkempi promptaus ja "ch√§t" interaktio k√§ytt√§j√§n kanssa tekstill√§ ja testataan eri teko√§lymalleja. T√§ss√§ esimerkiss√§ on testattu Mistral 7B v0.3, Gemma 3 4B, Dolphin3.0 Llama3.2 3B ja Llama3.1 8B Uncensored -GGUF malleja.
  
Resursseja s√§√§stet√§√§n, kun k√§ytet√§√§n esimerkiksi pienemp√§√§ 3B mallia, jonka teht√§v√§ on vastata nopeasti k√§ytt√§j√§n l√§hett√§miin PDF tiedostoihin. Ei tarvita suomen kielt√§ tai muuta osaamista. Teko√§lylle on m√§√§r√§tty hakea vain tietoja ja vastata tietojen perusteella.
  
GGUF mallit:
  
- [gemma3-4b-it-abliterated.Q4_K_M.gguf](https://huggingface.co/mlabonne/gemma-3-4b-it-abliterated-GGUF)
- [Dolphin3.0-Llama3.2-3B-Q4_K_M.gguf](https://huggingface.co/bartowski/Dolphin3.0-Llama3.2-3B-GGUF)
- [Reasoning / Thinking malli: Qwen3-1.7B-abliterated-iq4_nl.gguf](https://huggingface.co/Mungert/Qwen3-1.7B-abliterated-GGUF)
  
Embedding mallit:
  
- [all-MiniLM-L6-v2](https://huggingface.co/leliuga/all-MiniLM-L6-v2-GGUF)
- [nomic-embed-text-v1.5.Q8_0.gguf](https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF)
- [nomic-embed-text-v1.5.Q4_K_M.gguf](https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF)
- [nomic-embed-text-v2-moe.Q8_0.gguf](https://huggingface.co/nomic-ai/nomic-embed-text-v2-moe-GGUF)
  
  
### Testattu:
  
- Python 3.11.11
- llama-cpp-python versiot: 0.3.6 - 0.3.9
- nvcc versio: 12.8
- NumPy versio: 2.2.5
- Vulkan 1.4x?
  
Seuraavassa prosessissa testataan kuinka voitaisiin eka prosessoida pdfplumberilla PDF tiedostot, etsi√§ point-of-intrest ja my√∂s mahdollisesti testata OpenCV:t√§ tai muita OCR (kuvantunnistus) sovelluksia.
  
## Huomioitavaa asennuksessa:

### CMAKE
  
T√§ytyy olla asennettuna, ett√§ pystyt√§√§n Llama-cpp-python. [CPP compiler](https://visualstudio.microsoft.com/vs/features/cplusplus/) ja [visuaaliset ohjeet](https://code.visualstudio.com/docs/cpp/config-msvc#_prerequisites) Compilerin asennukselle.
  
### Vulkan / CUDA
  
Viimeisimm√§t n√§yt√∂nohjain ajurit t√§ytyy olla asennettuna. Cuda-toolkit t√§ytyy ladata erikseen Nvidian omilta sivuilta: https://developer.nvidia.com/cuda-downloads 
  
### Conda /miniconda/ anaconda asetuksia ja s√§√§t√∂j√§:
  
Muista PATH / Enviroment Variables...
  
Powershell: Poistamalla rajoitteita `set-executionpolicy remotesigned` ett√§ pystyt√§√§n avaamaan PowerShellill√§/Visual Studio Codella
esim. `conda activate gguf` automaattisesti. Pystyt√§√§n helpommin hallitsemaan VENVej√§ ilman, ett√§ tarvitsee vaihdella CMD ja
PS v√§lill√§. My√∂s helpompi laittaa `$env: ...` komentoja ja asentaa Vulkan tai Cuda versio Llama.cpp.pythonista.
  
`conda config --set auto_activate_base false` ottaa pois automaattisen aktivoinnin kun avataan esim Powershell tietokoneella.
  
### Python UV venv
  
Yksinkertainen asentaa noudattaen Astral-sh uv [GitHub repository√§](https://github.com/astral-sh/uv/).
  
`CMAKE_ARGS="-DGGML_VULKAN=on" uv pip install llama-cpp-python==0.3.9 --verbose --reinstall --no-cache-dir`
  
### Windows Powershell terminaaliin:
  
Aktivoi venv `conda activate tekoalyllama` korvaamalla `tekoalyllama` omalla virtuaaliymp√§rist√∂ll√§.
  
AMD tai Intel tai muu GPU: `$env:CMAKE_ARGS="-DGGML_VULKAN=on"` Windowsilla aktivoidaan Vulkan ajurien asentaminen.
  
Nvidia GPU: T√§ytyy olla asennettuna Cuda Toolkit: https://developer.nvidia.com/cuda-downloads ja sen j√§lkeen: `$env:CMAKE_ARGS="-DGGML_CUDA=on"`
  
### Llama-cpp-pythonin asennus:
  
Antamalla halutun arvon `$env:CMAKE_ARGS=` kohtaan, voidaan asentaa llama-cpp-python: `pip install llama-cpp-python --no-cache-dir --verbose` Tarvittaessa k√§yt√§ `--force` jos pit√§√§ overwritett√§√§ edellinen asennus.
  
  
## Mit√§ muutettavaa?
  
```
# Build a context prompt from the retrieved chunks.
context = "\n---\n".join(chunk["chunk"] for chunk in relevant_chunks)
    prompt = (
        "Answer the question based solely on the following context. List information of prof.nr. and other dimensional details.\n"
        "Context:\n"
        f"{context}\n\n"
        f"Question: {query}\n"
        "Answer:"
    )
```
  
- Muutettava promptia ja testata erillaisia promptaus kikkoja datan laadun varmistamiseen.
- Tokenien m√§√§r√§ on suuri jopa yhdell√§ PDF:ll√§. Dynaaminen CHUNK ja OVERLAP arvot?
  
## Mit√§ lis√§tt√§v√§√§?
  
### Chatting
  
Hoidettu: üëç
  
- Koodi `pdf_file_process_gguf_v4.py` tarvitsee "ch√§tt√§ys" lis√§yksen, ett√§ voidaan testata embedding toimivuutta. 
- Uusin v6 versio on chatting ominaisuus ja kysyy, k√§ytet√§√§nk√∂ jo valmiiksi prosessoituja PDF -tiedostoja.
- Testataan muita vektorien vertailu metodeja. Esim [FAISS vs Cosine_similarity](https://myscale.com/blog/faiss-cosine-similarity-enhances-search-efficiency/) 
  
### Vektori kartta
  
Mahdollisesti parantaa vektorikarttaa, riippuen kuinka monta tiedostoa tai kuinka suuria tiedostom√§√§ri√§ k√§sitell√§√§n.
  
```
def cosine_similarity(vec1, vec2):
    """Compute cosine similarity between two vectors."""
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2) + 1e-10)

def build_vector_store(embedding_model, pdf_texts):
    """
    For each PDF file‚Äôs text, break it into chunks and build a vector store.
    Each entry in the store is a dict containing the text chunk, its embedding, and the source filename.
    """
```
  
### Database | Dataset
  
- Database manuaalisesti alumiiniprofiilesita.
- Funktiokoodattu tietojen haku. T√§t√§ vertaillaan mahdollisella SQL-tietojen haulla ja verrataan, onko PDF tiedostoissa / s√§hk√∂posteissa samoja tietoja.

